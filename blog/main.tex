\documentclass[11pt]{article}
\usepackage[a4paper,margin=1.5in]{geometry}
\usepackage{inconsolata}  % Monospace font
\usepackage{setspace}
\onehalfspacing  % Increased line spacing
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{minted} % For code snippets; requires -shell-escape
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, calc, shapes.geometric}
\usepackage[table]{xcolor}
\usepackage{array, rotating, colortbl, booktabs}
\usepackage{adjustbox}
\usepackage{caption}
\newcommand{\cmdA}{\ensuremath{\mathsf{A}}} % Command: Attack
\newcommand{\cmdR}{\ensuremath{\mathsf{R}}} % Command: Retreat
\newcommand{\loyal}{\ensuremath{\mathcal{L}}}
\newcommand{\traitor}{\ensuremath{\mathcal{T}}}
\newcommand{\gen}[1]{\ensuremath{G_{#1}}}
% --- Definitions for storing and measuring the table and labels ---
\newsavebox{\mainTableBox}
\newlength{\mainTableHeight}
\newlength{\mainTableWidth}
\newlength{\senderLabelAreaHeight}
\newlength{\majorityLabelAreaHeight}
\usepackage{enumitem}
\usepackage{datetime2}
\usepackage{ragged2e}

% Header and Footer - Blog style
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\texttt{\large Byzantine Bytes}}
\fancyhead[C]{}
\fancyhead[R]{\texttt{\thepage}}
\renewcommand{\headrulewidth}{0.5pt}
\setlength{\headheight}{15pt}

% Metadata
\title{\texttt{\LARGE Byzantine Generals' Problem: \\[0.3em] \Large Decrypting Leslie Lamports' Solution}}
% \author{\texttt{\large A Technical Blog Post}}
% \date{\texttt{\large \today}}
\date{}

\begin{document}

\maketitle

\begin{center}
\begin{minipage}{0.85\textwidth}
\texttt{\large This blog explains Leslie Lamport's solution to the Byzantine Generals' problem that uses unsigned messages, providing a step-by-step walkthrough with visual examples.}
\end{minipage}
\end{center}
\vspace{1em}

\section*{\texttt{\Large Motivation}}
\justifying
Distributed systems are everywhere in our modern digital infrastructure—from cloud computing to blockchain networks. However, a fundamental challenge in these systems is achieving consensus when some components might be faulty or malicious.

The Byzantine Generals' Problem, introduced by Leslie Lamport, Robert Shostak, and Marshall Pease in 1982, elegantly captures this challenge through a military metaphor. Understanding this problem and its solution is crucial for anyone working with distributed systems, blockchain technology, or fault-tolerant computing.

This blog focuses specifically on the solution using unsigned messages—the most challenging scenario where messages carry no authentication. We'll examine a non-trivial instance with the most adversarial case: where the commander is a traitor and strategically sends conflicting commands to create maximum confusion.

The unsigned message solution is particularly fascinating because it operates under the loosest guarantees. Unlike solutions that rely on cryptographic signatures or other forms of authentication, this approach must achieve consensus through pure logic and majority reasoning, making it both intellectually stimulating and practically relevant.
\section*{\texttt{\Large Introduction}}
\justifying
Imagine a scenario where several Byzantine generals have surrounded an enemy city. They must decide collectively whether to attack or retreat. To succeed, all loyal generals must agree on the same plan of action—either all attack or all retreat. A split decision would be disastrous.

The generals can only communicate through messengers, and some generals might be traitors (including potentially the commanding general) who seek to prevent the loyal generals from reaching agreement. These traitors can:
\begin{itemize}
    \item Send different messages to different generals
    \item Collude with other traitors
    \item Lie about messages they claim to have received
\end{itemize}

The challenge is to design an algorithm that ensures all loyal generals reach the same decision despite these traitors. This is the essence of the Byzantine Generals' Problem.

The solution we'll explore doesn't rely on message signatures or authentication. Instead, it uses a recursive message-passing approach called Oral Message (OM) algorithm that can withstand up to $t$ traitors in a system with at least $3t+1$ generals.

\section*{\texttt{\Large Terminology}}
\justifying
Before diving into the solution, let's establish some terminology:

\begin{itemize}
    \item \textbf{Generals}: The participants in the system, denoted as $G_i$ where $i$ is the general's identifier.
    \item \textbf{Commander}: The general who initiates the decision process (usually $G_0$).
    \item \textbf{Lieutenants}: All other generals who must follow the commander's decision.
    \item \textbf{Loyal ($\mathcal{L}$)}: Generals who follow the algorithm correctly.
    \item \textbf{Traitors ($\mathcal{T}$)}: Generals who may behave arbitrarily and maliciously.
    \item \textbf{Commands}: The possible decisions, typically Attack (\textbf{A}) or Retreat (\textbf{R}).
    \item \textbf{OM($m$)}: The Oral Message algorithm with recursion depth $m$.
\end{itemize}

The Byzantine Generals' Problem has two key requirements:
\begin{enumerate}
    \item \textbf{Agreement}: All loyal generals must agree on the same decision. On receiving equal number of attack and retreat messages the loyal generals default to predetermined decision, $Retreat$
    \item \textbf{Validity}: If the commander is loyal, all loyal generals must follow the commander's order.
\end{enumerate}

Lamport proved that with oral (unsigned) messages, we need at least $3t+1$ generals to tolerate $t$ traitors, and the algorithm requires $t+1$ rounds of message exchanges.

\section*{\texttt{\Large The Algorithm}}
\justifying
The Oral Message algorithm (OM) works recursively:

\textbf{OM(0)}: The commander sends a value to all lieutenants, and each lieutenant uses the value received.

\textbf{OM($m$)}, for $m > 0$:
\begin{enumerate}
    \item The commander sends a value to each lieutenant.
    \item Each lieutenant acts as a commander in the OM($m-1$) algorithm to share the value they received with all other lieutenants.
    \item Each lieutenant determines the majority value reported for each general and uses that as their final decision.
\end{enumerate}

The algorithm guarantees correct operation if $n \geq 3t+1$ where $n$ is the total number of generals and $t$ is the maximum number of traitors.
The recursive nature of this algorithm creates a tree of message exchanges that grows exponentially with $m$. For a system with $n$ generals, the message complexity is $O(n^{m+1})$, which makes it practical only for small values of $t$ and thus $m$.

\section*{\texttt{\Large The Problem}}
\justifying
Let's examine a specific instance of the Byzantine Generals' Problem:

\begin{itemize}
    \item \textbf{Total generals}: $N = 7$
    \item \textbf{Traitors}: $t = 2$
    \item \textbf{Loyal generals}: $N - t = 5$
\end{itemize}

In our scenario:
\begin{itemize}
    \item Commander $G_0$ is a traitor
    \item Lieutenant $G_1$ is also a traitor
    \item Lieutenants $G_2$ through $G_6$ are loyal
\end{itemize}

This is a particularly challenging case because the commander, who initiates the algorithm, is malicious. The commander's strategy is to create maximum confusion by sending conflicting commands:
\begin{itemize}
    \item Commander $G_0$ sends Attack (A) to generals $G_2$, $G_4$, and $G_6$
    \item Commander $G_0$ sends Retreat (R) to generals $G_1$, $G_3$, and $G_5$
\end{itemize}

Additionally, the second traitor $G_1$ will also attempt to confuse the loyal generals by inconsistently relaying messages during the second round.

With $t = 2$ traitors, we need at least $3t+1 = 7$ generals, which is exactly what we have. According to the theory, OM(2) should be sufficient to achieve consensus among loyal generals. Let's see how this works in practice.

\section*{\texttt{\Large The Algorithm in Play}}

\subsection*{\texttt{\large Round 1}}
\justifying
In the first round, the commander $\gen{0}$ (who is a traitor) sends commands to all lieutenants. Since the commander is a traitor, they can send different commands to different lieutenants. Figure 1 illustrates what happens in Round 1:

\begin{center}
    \input{traitor_commander_round_1_fig}
\end{center}

\justifying
As shown in the diagram, the traitor commander $\gen{0}$ sends:
\begin{itemize}
    \item Retreat (R) to generals $\gen{1}$ (traitor), $\gen{3}$, and $\gen{5}$
    \item Attack (A) to generals $\gen{2}$, $\gen{4}$, and $\gen{6}$
\end{itemize}

At this point, each lieutenant only knows what the commander told them directly. The table in Figure 1 represents this initial knowledge state, with each lieutenant recording their received command on the diagonal.

\subsection*{\texttt{\large Round 2}}
\justifying
For this instance of the problem as $m=2$, the second round will constitute the $O(0)$ round (The final round).
In the second round, each lieutenant takes turns acting as the commander for the round and tells all other lieutenants what command they received from the original commander in Round 1.
Note that this round effectively becomes a ``he said, she said'' situation. Note that each lieutenant while acting as the commander does not send out any new commands, but instead just reports what they claim the commander of the previous round (In this case, the original commander $\gen{0}$) told them, regardless of whether that claim is truthful.

Figure 2 illustrates a scenario where a traitor lieutenant sends conflicting messages during Round 2. The rows and columns for the lieutenant who is acting as the commander (In this case, $\gen{1}$) are greyed out as they have already played their role by relaying the messages that they received from the commander of the previous round and do not participate in the consensus that follows. The diagonal in the table contains the value that the lieutenant received from the acting commander for the round.

\begin{center}
    \input{traitor_commander_traitor_round_2_fig}
\end{center}

\justifying
The majority from round $O(m-1)$ is then used as the truth in $O(m)$.\\

In a different scenario, we can observe how a loyal lieutenant shares consistent information during Round 2:

\input{traitor_commander_loyal_round_2}

\justifying
After all lieutenants have completed their communications in Round 2, the final information state of each general is represented in the following table:

\begin{center}
    \input{traitor_commander_final_table_fig}
\end{center}

\justifying
To summarize, The traitor lieutenant $\gen{1}$ (who received ``Retreat'' from $\gen{0}$) continues the deception by:
\begin{itemize}
    \item Telling some lieutenants that it received ``Attack'' from the commander
    \item Telling other lieutenants that it received ``Retreat'' from the commander
\end{itemize}

Meanwhile, all loyal lieutenants honestly relay the commands they received. After this round, each lieutenant has:
\begin{itemize}
    \item Their original command from the commander (from Round 1)
    \item Reports from all other lieutenants about what they claim to have received
\end{itemize}

The final table shows what each lieutenant knows after all Round 2 messages have been exchanged. The cell values show what message was conveyed.
Now, each loyal lieutenant can determine what command to follow by taking a majority vote of all reported values. The consensus among all loyal lieutenants is to ``Retreat'' (R).
This demonstrates the power of the OM(2) algorithm: despite having a traitor commander and a traitor lieutenant, all loyal lieutenants reach the same conclusion. The Byzantine Generals' Problem is solved for this instance!

\section*{\texttt{\Large A Second Example: Loyal Commander with Collaborating Traitors}}

\justifying
Let's examine another crucial scenario where the commander is loyal but traitor lieutenants collaborate to disrupt consensus. This scenario demonstrates the algorithm's effectiveness at satisfying the validity condition when the commander is loyal.

\begin{itemize}
    \item \textbf{Total generals}: $N = 7$
    \item \textbf{Traitors}: $t = 2$
    \item \textbf{Loyal generals}: $N - t = 5$
\end{itemize}

In this scenario:
\begin{itemize}
    \item Commander $\gen{0}$ is loyal
    \item Lieutenants $\gen{1}$ and $\gen{4}$ are traitors
    \item Lieutenants $\gen{2}$, $\gen{3}$, $\gen{5}$, and $\gen{6}$ are loyal
\end{itemize}

We'll execute the OM(2) algorithm for this scenario and observe how the loyal lieutenants achieve consensus despite the traitors' attempts to disrupt it.

\subsection*{\texttt{\large Round 1: Loyal Commander Sends Consistent Messages}}
\justifying
In the first round, the loyal commander $\gen{0}$ sends the same command to all lieutenants. In this case, the commander chooses Attack (A). Figure 3 illustrates what happens in Round 1:

\input{loyal_commander_round_1_fig}

\justifying
As shown in the diagram, the loyal commander $\gen{0}$ sends consistent Attack (A) messages to all lieutenants, including the two traitors ($\gen{1}$ and $\gen{4}$).
At this point, each lieutenant only knows what the commander told them directly. The table in Figure 3 represents this initial knowledge state, with each lieutenant recording their received command in their own diagonal cell. Since the commander is loyal in our scenario, all cells contain Attack (A) commands. The off-diagonal cells remain empty because the lieutenants haven't yet exchanged messages with each other.

\subsection*{\texttt{\large Round 2: Traitors Attempt to Disrupt Consensus}}
\justifying
In the second round, each lieutenant acts as the commander for the round and tells all other lieutenants what command they received from the original commander in Round 1.
Figure 4 illustrates how traitors attempt to contradict the commander's orders during Round 2:


\input{loyal_commander_traitor_round_2_fig}

\justifying
In another scenario, we see how loyal lieutenants faithfully relay the commander's original message:

\input{loyal_commander_loyal_round_2_fig}

\justifying
After all lieutenants have exchanged their information, we can represent the final state of knowledge with the following comprehensive table:

\input{loyal_commander_final_table}

\justifying
This is where the traitors' malicious behavior becomes evident. Despite both traitor lieutenants ($\gen{1}$ and $\gen{4}$) receiving Attack (A) from the loyal commander, they attempt to create confusion:

\begin{itemize}
    \item Traitor $\gen{1}$ consistently contradicts the commander by telling all other lieutenants that it received "Retreat" (R) instead of the actual "Attack" (A) command

    \item Similarly, traitor $\gen{4}$ also sends false information, telling all other lieutenants it received "Retreat" (R) when it actually received "Attack" (A)
\end{itemize}

Meanwhile, all loyal lieutenants ($\gen{2}$, $\gen{3}$, $\gen{5}$, and $\gen{6}$) honestly relay the Attack (A) command they received from the commander.

After this round, each lieutenant has:
\begin{itemize}
    \item Their original command from the commander (from Round 1)
    \item Reports from all other lieutenants about what they claim to have received
\end{itemize}

The final table shows what each lieutenant knows after all Round 2 messages have been exchanged. The diagonal cells (highlighted in yellow) show what each lieutenant itself received from the commander. The off-diagonal cells show what each lieutenant was told by others.

Now, each loyal lieutenant can determine what command to follow by taking a majority vote of all reported values. As shown in the "Majority" row of the table, despite the conflicting information from the traitors, all loyal lieutenants reach the same conclusion: Attack (A), which matches the loyal commander's original order.

This demonstrates an important aspect of the OM(2) algorithm: when the commander is loyal, the algorithm ensures that all loyal lieutenants follow the commander's order, even if traitor lieutenants attempt to disrupt the process. The algorithm successfully satisfies both the Agreement and Validity requirements.

% \subsection{Code Example}
%
% Here's a Python code snippet using the \texttt{minted} package:
%
% \begin{minted}[fontsize=\small, bgcolor=gray!10, linenos]{python}
% def hello_world():
%     print("Hello, world!")
% \end{minted}

% \subsection{Including Images}
%
% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.6\textwidth]{example-image}
%     \caption{Sample image included in the blog post.}
% \end{figure}

\section*{\texttt{\Large Conclusion}}

\justifying
The Byzantine Generals' Problem represents one of the fundamental challenges in distributed computing. Through our examination of the Oral Message algorithm (OM), we've seen how it's possible to achieve consensus even in the presence of malicious actors.

Key insights from our exploration:

\begin{itemize}
    \item With $n$ generals and at most $t$ traitors, consensus requires $n \geq 3t+1$ and $m \geq t$ rounds of communication.
    \item The recursive nature of the algorithm allows loyal generals to filter out inconsistent information.
    \item Even with a traitor commander sending contradictory commands, loyal generals can still reach agreement.
    \item The solution works without requiring any form of message authentication or signatures.
\end{itemize}

This algorithm laid the foundation for many fault-tolerant distributed systems we rely on today, from cloud databases to blockchain networks. Modern consensus protocols like Practical Byzantine Fault Tolerance (PBFT) and those used in blockchain systems are direct descendants of Lamport's original solution.

Understanding these principles not only helps in designing robust distributed systems but also provides insight into the fundamental limits of what's achievable in the presence of Byzantine failures.

\end{document}
